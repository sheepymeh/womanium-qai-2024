{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Classifier with Pennylane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(necessary to pass the project) To familiarize yourself with the basic workflow in Quantum Machine Learning, work through the tutorial on Variational Classifier. Implement and present the usual steps in this workflow and explain in your own words the purpose of each step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This task follows the [Variational Classifier tutorial](https://pennylane.ai/qml/demos/tutorial_variational_classifier/) by Pennylane. Building on what is taught, we create a QML model for the full iris dataset involving 3 types of irises (instead of only 2) and 4 features (instead of only the first 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.optimize import NesterovMomentumOptimizer\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we download [the iris dataset](https://www.kaggle.com/datasets/uciml/iris) from Kaggle, and load it with some processing. Our quantum classifier can output values between 0 to 1, however since our iris species is a categorical variable, it is not ideal to give them sequential values. Hence, we decide to employ one-hot encoding with the last 2 columns of our data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "data = []\n",
    "with open('variational_classifier/data/Iris.csv', newline='') as csvfile:\n",
    "    spamreader = csv.DictReader(csvfile, delimiter=',')\n",
    "    for row in spamreader:\n",
    "        data_row = [float(row['SepalLengthCm']), float(row['SepalWidthCm']), \n",
    "                float(row['PetalLengthCm']), float(row['PetalWidthCm']), \n",
    "                1 if row['Species'] == 'Iris-setosa' else -1,\n",
    "                1 if row['Species'] == 'Iris-versicolor' else -1]\n",
    "\n",
    "        data.append(data_row)\n",
    "\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the tutorial, we need to pad our X data so that relative difference between each X data point (or each row of data) is still preserved after normalisation. Since we already has 4 features (using 2 qubits), we add an extra qubit for the padding such that our vector size is $2^3 = 8$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First X sample (original)  : [5.1 3.5 1.4 0.2]\n",
      "First X sample (padded)    : [5.1 3.5 1.4 0.2 0.1 0.1 0.1 0.1]\n",
      "First X sample (normalized): [0.80337378 0.55133495 0.22053398 0.03150485 0.01575243 0.01575243\n",
      " 0.01575243 0.01575243]\n"
     ]
    }
   ],
   "source": [
    "Y1 = data[:, 4]\n",
    "Y2 = data[:, 5]\n",
    "\n",
    "X = data[:, 0:4]\n",
    "print(f\"First X sample (original)  : {X[0]}\")\n",
    "\n",
    "# pad the vectors to size 2^3=8 with constant values\n",
    "padding = np.ones((len(X), 4)) * 0.1\n",
    "X_pad = np.c_[X, padding]\n",
    "print(f\"First X sample (padded)    : {X_pad[0]}\")\n",
    "\n",
    "# normalize each input\n",
    "normalization = np.sqrt(np.sum(X_pad**2, 1)) # finds euclidean length\n",
    "X_norm = (X_pad.T / normalization).T\n",
    "print(f\"First X sample (normalized): {X_norm[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define some helper functions. We utilise Pennylane's Amplitude Embedding function to directly prepare the states corresponding to our data points. We also utilise the same quantum layers used for the tutorial for simplicity, although they can be altered assuming that entanglement still occurs.\n",
    "\n",
    "From this circuit, we can return the expectation and add a trainable bias to capture any biases in our model or in the dataset. We use the same functions given in the tutorial to calculate the cost of our circuit, which we define to be the square loss for our model. The accuracy function allows us to assess our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device('default.qubit')\n",
    "\n",
    "def state_preparation(x):\n",
    "    qml.AmplitudeEmbedding(features=x, wires=range(3), normalize=True)\n",
    "\n",
    "\n",
    "def layer(layer_weights):\n",
    "    for wire in range(3):\n",
    "        qml.Rot(*layer_weights[wire], wires=wire)\n",
    "    for pair in [[0, 1], [1, 2], [2, 0]]:\n",
    "        qml.CNOT(wires=pair)\n",
    "\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def circuit(weights, x):\n",
    "    state_preparation(x)\n",
    "\n",
    "    for layer_weights in weights:\n",
    "        layer(layer_weights)\n",
    "\n",
    "    return qml.expval(qml.PauliZ(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variational_classifier(weights, bias, x):\n",
    "    return circuit(weights, x) + bias\n",
    "\n",
    "def square_loss(labels, predictions):\n",
    "    # We use a call to qml.math.stack to allow subtracting the arrays directly\n",
    "    return np.mean((labels - qml.math.stack(predictions)) ** 2)\n",
    "\n",
    "def cost(weights, bias, X, Y):\n",
    "    predictions = [variational_classifier(weights, bias, x) for x in X]\n",
    "    return square_loss(Y, predictions)\n",
    "\n",
    "def accuracy(labels, predictions):\n",
    "    acc = sum(abs(l - p) < 1e-5 for l, p in zip(labels, predictions))\n",
    "    acc = acc / len(labels)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we employed one-hot encoding with two variables (whether the species is Iris-setosa or not and whether the species is Iris-versicolor or not), we will create two QML models to classify for each variable. \n",
    "\n",
    "These two QML models are meant to be sequential and considered together to form a larger classifier. We will directly use the outputs in the first model when processing the input data for the second model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_data = len(Y1)\n",
    "num_train = int(0.75 * num_data)\n",
    "index = np.random.permutation(range(num_data))\n",
    "X_train = X_norm[index[:num_train]]\n",
    "Y1_train = Y1[index[:num_train]]\n",
    "X_val = X_norm[index[num_train:]]\n",
    "Y1_val = Y1[index[num_train:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubits = 3\n",
    "num_layers = 6\n",
    "\n",
    "weights_init = 0.01 * np.random.randn(num_layers, num_qubits, 3, requires_grad=True)\n",
    "bias_init = np.array(0.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:     2 | Cost: 1.9806145 | Acc train: 0.3392857 | Acc validation: 0.3157895\n",
      "Iter:     4 | Cost: 1.7449219 | Acc train: 0.3392857 | Acc validation: 0.3157895\n",
      "Iter:     6 | Cost: 1.4196121 | Acc train: 0.0089286 | Acc validation: 0.0000000\n",
      "Iter:     8 | Cost: 1.2482700 | Acc train: 0.6071429 | Acc validation: 0.5789474\n",
      "Iter:    10 | Cost: 1.2433723 | Acc train: 0.6607143 | Acc validation: 0.6842105\n",
      "Iter:    12 | Cost: 1.3268026 | Acc train: 0.6607143 | Acc validation: 0.6842105\n",
      "Iter:    14 | Cost: 1.2540876 | Acc train: 0.6607143 | Acc validation: 0.6842105\n",
      "Iter:    16 | Cost: 1.1414321 | Acc train: 0.6607143 | Acc validation: 0.6842105\n",
      "Iter:    18 | Cost: 1.0441755 | Acc train: 0.6607143 | Acc validation: 0.6842105\n",
      "Iter:    20 | Cost: 0.9486916 | Acc train: 0.6607143 | Acc validation: 0.6842105\n",
      "Iter:    22 | Cost: 0.8696014 | Acc train: 0.6607143 | Acc validation: 0.6842105\n",
      "Iter:    24 | Cost: 0.7674455 | Acc train: 0.6607143 | Acc validation: 0.6842105\n",
      "Iter:    26 | Cost: 0.6786418 | Acc train: 0.6607143 | Acc validation: 0.6842105\n",
      "Iter:    28 | Cost: 0.5975113 | Acc train: 0.6696429 | Acc validation: 0.6842105\n",
      "Iter:    30 | Cost: 0.5260529 | Acc train: 0.7321429 | Acc validation: 0.7894737\n",
      "Iter:    32 | Cost: 0.4803606 | Acc train: 0.6607143 | Acc validation: 0.7105263\n",
      "Iter:    34 | Cost: 0.4485034 | Acc train: 0.6696429 | Acc validation: 0.7368421\n",
      "Iter:    36 | Cost: 0.4269880 | Acc train: 0.6785714 | Acc validation: 0.7368421\n",
      "Iter:    38 | Cost: 0.3817574 | Acc train: 0.9732143 | Acc validation: 1.0000000\n",
      "Iter:    40 | Cost: 0.3674553 | Acc train: 1.0000000 | Acc validation: 1.0000000\n",
      "Iter:    42 | Cost: 0.3578287 | Acc train: 1.0000000 | Acc validation: 1.0000000\n",
      "Iter:    44 | Cost: 0.3477550 | Acc train: 1.0000000 | Acc validation: 1.0000000\n",
      "Iter:    46 | Cost: 0.3298426 | Acc train: 1.0000000 | Acc validation: 1.0000000\n",
      "Iter:    48 | Cost: 0.3303392 | Acc train: 1.0000000 | Acc validation: 1.0000000\n",
      "Iter:    50 | Cost: 0.3263498 | Acc train: 1.0000000 | Acc validation: 1.0000000\n",
      "Iter:    52 | Cost: 0.3180142 | Acc train: 1.0000000 | Acc validation: 1.0000000\n",
      "Iter:    54 | Cost: 0.3259716 | Acc train: 1.0000000 | Acc validation: 1.0000000\n",
      "Iter:    56 | Cost: 0.3199883 | Acc train: 1.0000000 | Acc validation: 1.0000000\n",
      "Iter:    58 | Cost: 0.3204013 | Acc train: 1.0000000 | Acc validation: 1.0000000\n",
      "Iter:    60 | Cost: 0.3170198 | Acc train: 1.0000000 | Acc validation: 1.0000000\n"
     ]
    }
   ],
   "source": [
    "opt = NesterovMomentumOptimizer(0.01)\n",
    "batch_size = 5\n",
    "\n",
    "# train the variational classifier\n",
    "weights = weights_init\n",
    "bias = bias_init\n",
    "for it in range(60):\n",
    "    # Update the weights by one optimizer step\n",
    "    batch_index = np.random.randint(0, num_train, (batch_size,))\n",
    "    X_train_batch = X_train[batch_index]\n",
    "    Y1_train_batch = Y1_train[batch_index]\n",
    "    weights, bias, _, _ = opt.step(cost, weights, bias, X_train_batch, Y1_train_batch)\n",
    "\n",
    "    # Compute predictions on train and validation set\n",
    "    predictions_train = [np.sign(variational_classifier(weights, bias, X_train[i])) for i in range(len(X_train))]\n",
    "    predictions_val = [np.sign(variational_classifier(weights, bias, X_val[i])) for i in range(len(X_val))]\n",
    "\n",
    "    # Compute accuracy on train and validation set\n",
    "    acc_train = accuracy(Y1_train, predictions_train)\n",
    "    acc_val = accuracy(Y1_val, predictions_val)\n",
    "\n",
    "    if (it + 1) % 2 == 0:\n",
    "        _cost = cost(weights, bias, X_norm, Y1)\n",
    "        print(\n",
    "            f\"Iter: {it + 1:5d} | Cost: {_cost:0.7f} | \"\n",
    "            f\"Acc train: {acc_train:0.7f} | Acc validation: {acc_val:0.7f}\"\n",
    "        )\n",
    "\n",
    "weights1 = weights\n",
    "bias1 = bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see from the above that our model has a 100% accuracy when classifying for whether the species is Iris-Setosa! We save our model's trained weights and bias into the variables weights1 and bias1 for future prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next model classifies for whether a datapoint is that of species Iris-versicolor, and from our first model we already have some datapoints classified as Iris-setosa which we can eliminate from the second model. The following code shows the data processing for our second model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 8)\n"
     ]
    }
   ],
   "source": [
    "# data processing after the first QML model\n",
    "\n",
    "predictions = [np.sign(variational_classifier(weights1, bias1, X_norm[i])) for i in range(len(X_norm))]\n",
    "\n",
    "\n",
    "num_data = len(Y1)\n",
    "num_train = int(0.75 * num_data)\n",
    "\n",
    "X2 = X_norm[[True if prediction == -1 else False for prediction in predictions]]\n",
    "print(np.shape(X2))\n",
    "Y2 = Y2[[True if prediction == -1 else False for prediction in predictions]]\n",
    "\n",
    "\n",
    "num_data = len(Y2)\n",
    "num_train = int(0.75 * num_data)\n",
    "index = np.random.permutation(range(num_data))\n",
    "X2_train = X2[index[:num_train]]\n",
    "X2_val = X2[index[num_train:]]\n",
    "Y2_train = Y2[index[:num_train]]\n",
    "Y2_val = Y2[index[num_train:]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the gradient descent methods were unsuitable for classifying categorical data, especially since Iris-versicolor and the remaining Iris-virginica were much closer in their characteristics (Iris-setosa has drastic differences in its features compared to the other two). \n",
    "\n",
    "We tested out the optimizers AdagradOptimizer(0.05), SPSAOptimizer(), NesterovMomentumOptimizer(0.03), but the models producing the best results were NesterovMomentumOptimizer(0.01) and NesterovMomentumOptimizer(0.015), which were able to produce 70-80% validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:     2 | Cost: 1.4526274 | Acc train: 0.4800000 | Acc validation: 0.5600000\n",
      "Iter:     4 | Cost: 1.3249414 | Acc train: 0.4800000 | Acc validation: 0.5600000\n",
      "Iter:     6 | Cost: 1.1259806 | Acc train: 0.4800000 | Acc validation: 0.5600000\n",
      "Iter:     8 | Cost: 1.0547436 | Acc train: 0.4800000 | Acc validation: 0.5600000\n",
      "Iter:    10 | Cost: 1.0172980 | Acc train: 0.4800000 | Acc validation: 0.6000000\n",
      "Iter:    12 | Cost: 1.0037268 | Acc train: 0.5200000 | Acc validation: 0.5200000\n",
      "Iter:    14 | Cost: 1.0004456 | Acc train: 0.5200000 | Acc validation: 0.3200000\n",
      "Iter:    16 | Cost: 1.0179078 | Acc train: 0.5200000 | Acc validation: 0.4400000\n",
      "Iter:    18 | Cost: 1.0169162 | Acc train: 0.5200000 | Acc validation: 0.4400000\n",
      "Iter:    20 | Cost: 0.9969315 | Acc train: 0.5333333 | Acc validation: 0.4400000\n",
      "Iter:    22 | Cost: 0.9912207 | Acc train: 0.5333333 | Acc validation: 0.4400000\n",
      "Iter:    24 | Cost: 0.9875108 | Acc train: 0.5333333 | Acc validation: 0.4400000\n",
      "Iter:    26 | Cost: 0.9761190 | Acc train: 0.5466667 | Acc validation: 0.4400000\n",
      "Iter:    28 | Cost: 0.9661131 | Acc train: 0.5466667 | Acc validation: 0.4400000\n",
      "Iter:    30 | Cost: 0.9621384 | Acc train: 0.5466667 | Acc validation: 0.4400000\n",
      "Iter:    32 | Cost: 0.9403252 | Acc train: 0.7600000 | Acc validation: 0.6400000\n",
      "Iter:    34 | Cost: 0.9365080 | Acc train: 0.7066667 | Acc validation: 0.6800000\n",
      "Iter:    36 | Cost: 0.9299389 | Acc train: 0.7066667 | Acc validation: 0.6800000\n",
      "Iter:    38 | Cost: 0.9236785 | Acc train: 0.6933333 | Acc validation: 0.5200000\n",
      "Iter:    40 | Cost: 0.9604757 | Acc train: 0.5200000 | Acc validation: 0.4400000\n",
      "Iter:    42 | Cost: 0.9508517 | Acc train: 0.5200000 | Acc validation: 0.4400000\n",
      "Iter:    44 | Cost: 0.9150521 | Acc train: 0.5866667 | Acc validation: 0.4800000\n",
      "Iter:    46 | Cost: 0.9051243 | Acc train: 0.6800000 | Acc validation: 0.5600000\n",
      "Iter:    48 | Cost: 0.9009847 | Acc train: 0.6800000 | Acc validation: 0.5200000\n",
      "Iter:    50 | Cost: 0.8923626 | Acc train: 0.7866667 | Acc validation: 0.6800000\n",
      "Iter:    52 | Cost: 0.8865802 | Acc train: 0.8933333 | Acc validation: 0.6800000\n",
      "Iter:    54 | Cost: 0.8842782 | Acc train: 0.7733333 | Acc validation: 0.7200000\n",
      "Iter:    56 | Cost: 0.8816761 | Acc train: 0.7600000 | Acc validation: 0.6800000\n",
      "Iter:    58 | Cost: 0.8754624 | Acc train: 0.9466667 | Acc validation: 0.7600000\n",
      "Iter:    60 | Cost: 0.8740300 | Acc train: 0.8000000 | Acc validation: 0.7200000\n"
     ]
    }
   ],
   "source": [
    "opt = NesterovMomentumOptimizer(0.01)\n",
    "batch_size = 5\n",
    "\n",
    "# train the variational classifier\n",
    "weights = weights_init\n",
    "bias = bias_init\n",
    "for it in range(60):\n",
    "    # Update the weights by one optimizer step\n",
    "    batch_index = np.random.randint(0, num_train, (batch_size,))\n",
    "    X2_train_batch = X2_train[batch_index]\n",
    "    Y2_train_batch = Y2_train[batch_index]\n",
    "    weights, bias, _, _ = opt.step(cost, weights, bias, X2_train_batch, Y2_train_batch)\n",
    "\n",
    "    # Compute predictions on train and validation set\n",
    "    predictions_train = [np.sign(variational_classifier(weights, bias, X2_train[i])) for i in range(len(X2_train))]\n",
    "    predictions_val = [np.sign(variational_classifier(weights, bias, X2_val[i])) for i in range(len(X2_val))]\n",
    "\n",
    "    # Compute accuracy on train and validation set\n",
    "    acc_train = accuracy(Y2_train, predictions_train)\n",
    "    acc_val = accuracy(Y2_val, predictions_val)\n",
    "\n",
    "    if (it + 1) % 2 == 0:\n",
    "        _cost = cost(weights, bias, X2, Y2)\n",
    "        print(\n",
    "            f\"Iter: {it + 1:5d} | Cost: {_cost:0.7f} | \"\n",
    "            f\"Acc train: {acc_train:0.7f} | Acc validation: {acc_val:0.7f}\"\n",
    "        )\n",
    "\n",
    "weight2 = weights\n",
    "bias2 = bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:     2 | Cost: 1.4322826 | Acc train: 0.4800000 | Acc validation: 0.5600000\n",
      "Iter:     4 | Cost: 1.1172829 | Acc train: 0.4800000 | Acc validation: 0.5600000\n",
      "Iter:     6 | Cost: 1.0256163 | Acc train: 0.5066667 | Acc validation: 0.3200000\n",
      "Iter:     8 | Cost: 1.2844049 | Acc train: 0.5200000 | Acc validation: 0.4400000\n",
      "Iter:    10 | Cost: 1.6085753 | Acc train: 0.5200000 | Acc validation: 0.4400000\n",
      "Iter:    12 | Cost: 1.7212959 | Acc train: 0.5200000 | Acc validation: 0.4400000\n",
      "Iter:    14 | Cost: 1.5175456 | Acc train: 0.5200000 | Acc validation: 0.4400000\n",
      "Iter:    16 | Cost: 1.2334350 | Acc train: 0.5200000 | Acc validation: 0.4400000\n",
      "Iter:    18 | Cost: 1.0613616 | Acc train: 0.5200000 | Acc validation: 0.4400000\n",
      "Iter:    20 | Cost: 0.9811421 | Acc train: 0.5200000 | Acc validation: 0.3600000\n",
      "Iter:    22 | Cost: 0.9665639 | Acc train: 0.5466667 | Acc validation: 0.6800000\n",
      "Iter:    24 | Cost: 0.9743451 | Acc train: 0.4800000 | Acc validation: 0.5600000\n",
      "Iter:    26 | Cost: 0.9757115 | Acc train: 0.4800000 | Acc validation: 0.5600000\n",
      "Iter:    28 | Cost: 0.9515225 | Acc train: 0.4933333 | Acc validation: 0.5600000\n",
      "Iter:    30 | Cost: 0.9301112 | Acc train: 0.5466667 | Acc validation: 0.6000000\n",
      "Iter:    32 | Cost: 0.9061359 | Acc train: 0.8666667 | Acc validation: 0.6000000\n",
      "Iter:    34 | Cost: 0.9077144 | Acc train: 0.5600000 | Acc validation: 0.4800000\n",
      "Iter:    36 | Cost: 0.9207177 | Acc train: 0.5200000 | Acc validation: 0.4400000\n",
      "Iter:    38 | Cost: 0.9013733 | Acc train: 0.5466667 | Acc validation: 0.4800000\n",
      "Iter:    40 | Cost: 0.9099851 | Acc train: 0.5200000 | Acc validation: 0.5600000\n",
      "Iter:    42 | Cost: 0.8947273 | Acc train: 0.6133333 | Acc validation: 0.6800000\n",
      "Iter:    44 | Cost: 0.8949661 | Acc train: 0.5333333 | Acc validation: 0.4400000\n",
      "Iter:    46 | Cost: 0.9632953 | Acc train: 0.5200000 | Acc validation: 0.4400000\n",
      "Iter:    48 | Cost: 1.0260545 | Acc train: 0.5200000 | Acc validation: 0.4400000\n",
      "Iter:    50 | Cost: 1.0947677 | Acc train: 0.5200000 | Acc validation: 0.4400000\n",
      "Iter:    52 | Cost: 0.9931996 | Acc train: 0.5200000 | Acc validation: 0.4400000\n",
      "Iter:    54 | Cost: 0.8702722 | Acc train: 0.6266667 | Acc validation: 0.5600000\n",
      "Iter:    56 | Cost: 0.8613453 | Acc train: 0.8000000 | Acc validation: 0.6800000\n",
      "Iter:    58 | Cost: 0.8608664 | Acc train: 0.7466667 | Acc validation: 0.6800000\n",
      "Iter:    60 | Cost: 0.8558148 | Acc train: 0.9333333 | Acc validation: 0.8800000\n"
     ]
    }
   ],
   "source": [
    "opt = NesterovMomentumOptimizer(0.015)\n",
    "batch_size = 5\n",
    "\n",
    "# train the variational classifier\n",
    "weights = weights_init\n",
    "bias = bias_init\n",
    "for it in range(60):\n",
    "    # Update the weights by one optimizer step\n",
    "    batch_index = np.random.randint(0, num_train, (batch_size,))\n",
    "    X2_train_batch = X2_train[batch_index]\n",
    "    Y2_train_batch = Y2_train[batch_index]\n",
    "    weights, bias, _, _ = opt.step(cost, weights, bias, X2_train_batch, Y2_train_batch)\n",
    "\n",
    "    # Compute predictions on train and validation set\n",
    "    predictions_train = [np.sign(variational_classifier(weights, bias, X2_train[i])) for i in range(len(X2_train))]\n",
    "    predictions_val = [np.sign(variational_classifier(weights, bias, X2_val[i])) for i in range(len(X2_val))]\n",
    "\n",
    "    # Compute accuracy on train and validation set\n",
    "    acc_train = accuracy(Y2_train, predictions_train)\n",
    "    acc_val = accuracy(Y2_val, predictions_val)\n",
    "\n",
    "    if (it + 1) % 2 == 0:\n",
    "        _cost = cost(weights, bias, X2, Y2)\n",
    "        print(\n",
    "            f\"Iter: {it + 1:5d} | Cost: {_cost:0.7f} | \"\n",
    "            f\"Acc train: {acc_train:0.7f} | Acc validation: {acc_val:0.7f}\"\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qiskit-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
