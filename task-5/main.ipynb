{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import flax\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state\n",
    "import optax\n",
    "from transformers import AutoProcessor, FlaxResNetModel\n",
    "import dm_pix as pix\n",
    "import pennylane as qml\n",
    "\n",
    "from tqdm.auto import tqdm, trange\n",
    "from grain import python as pygrain\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "num_epochs = 10\n",
    "lr = 1e-4\n",
    "data_dir = 'data'\n",
    "seed = 42\n",
    "dataloader_workers = 2\n",
    "num_classes = 6\n",
    "qnn_wires = 4\n",
    "qnn_layers = 2\n",
    "image_size = 224\n",
    "mean = jnp.array([0.24085431])\n",
    "var = jnp.array([0.01992414])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_images(images: jax.Array) -> jax.Array:\n",
    "\timages /= 255\n",
    "\timages = jax.nn.standardize(images, mean=mean, variance=var, axis=(1, 2))\n",
    "\n",
    "\treturn images\n",
    "\n",
    "@jax.jit\n",
    "def train_transform(images: jax.Array, key: jax.Array) -> jax.Array:\n",
    "\tn, h, w, c = images.shape\n",
    "\n",
    "\timages = jax.image.resize(images, (n, 512, 512, c), method='bicubic')\n",
    "\timages = pix.random_flip_left_right(key, images)\n",
    "\timages = pix.random_flip_up_down(key, images)\n",
    "\timages = pix.random_crop(key, images, (n, image_size, image_size, c))\n",
    "\timages = normalize_images(images)\n",
    "\n",
    "\treturn images\n",
    "\n",
    "@jax.jit\n",
    "def test_transform(images: jax.Array, key: jax.Array) -> jax.Array:\n",
    "\tn, h, w, c = images.shape\n",
    "\n",
    "\timages = jax.image.resize(images, (n, image_size, image_size, c), method='bicubic')\n",
    "\timages = normalize_images(images)\n",
    "\n",
    "\treturn images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageTransform(pygrain.RandomMapTransform):\n",
    "\tdef __init__(self, transform_fn):\n",
    "\t\tself.transform_fn = transform_fn\n",
    "\n",
    "\tdef random_map(self, data: tuple[np.ndarray, np.ndarray], rng: np.random.Generator) -> tuple[jax.Array, jax.Array]:\n",
    "\t\timages, labels = data\n",
    "\t\timages, labels = jnp.array(images), jnp.array(labels)\n",
    "\n",
    "\t\tif len(images.shape) == 3:\n",
    "\t\t\timages = images[:, :, :, None]\n",
    "\n",
    "\t\tkey = jax.random.PRNGKey(rng.integers(0, 2**32))\n",
    "\t\timages = self.transform_fn(images, key)\n",
    "\t\treturn images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataSource(pygrain.RandomAccessDataSource[tuple[Image.Image, int]]):\n",
    "\tdef __init__(self, path, split, num_classes = 6):\n",
    "\t\tself.image_dir = os.path.join(path, split)\n",
    "\t\twith open(os.path.join(self.image_dir, f'{split}.json')) as f:\n",
    "\t\t\tdata = json.load(f)\n",
    "\t\t\tself.images = tuple(data.keys())\n",
    "\t\t\tself.labels = np.array(tuple(data.values()))\n",
    "\t\tself.num_classes = num_classes\n",
    "\n",
    "\tdef __len__(self) -> int:\n",
    "\t\treturn len(self.images)\n",
    "\n",
    "\tdef __getitem__(self, idx) -> tuple[Image.Image, int]:\n",
    "\t\timage_path = os.path.join(self.image_dir, self.images[idx])\n",
    "\t\timage = Image.open(image_path).convert('RGB')\n",
    "\t\tlabel = self.labels[idx].item()\n",
    "\t\treturn image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Index Sampler\n",
    "\n",
    "As the dataset is very imbalanced, we need to use a weighted sampler to ensure that each class is represented equally. This class is intended to work similarly to the [PyTorch Weighted Random Sampler](https://pytorch.org/docs/stable/data.html#torch.utils.data.WeightedRandomSampler)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedIndexSampler(pygrain.Sampler):\n",
    "\tdef __init__(self, weights: np.ndarray, seed: int, num_epochs: int = 1):\n",
    "\t\tassert num_epochs > 0\n",
    "\t\tself._num_records = len(weights)\n",
    "\t\tself._max_index = self._num_records * num_epochs\n",
    "\t\tself._weights = weights\n",
    "\t\tself._seed = seed\n",
    "\t\tself._rng = np.random.Generator(np.random.Philox(self._seed))\n",
    "\t\tself._record_keys = self._rng.choice(self._num_records, size=self._max_index, replace=True, p=self._weights)\n",
    "\n",
    "\tdef __getitem__(self, index: int) -> pygrain.RecordMetadata:\n",
    "\t\tif not 0 <= index < self._max_index:\n",
    "\t\t\traise IndexError(\n",
    "\t\t\t\tf\"RecordMetadata object index is out of bounds; Got index {index},\"\n",
    "\t\t\t\tf\" allowed indices should be in [0, {self._max_index}]\"\n",
    "\t\t\t)\n",
    "\n",
    "\t\trecord_key = self._record_keys[index]\n",
    "\t\trng = np.random.Generator(np.random.Philox(key=self._seed + index))\n",
    "\t\treturn pygrain.RecordMetadata(index, record_key, rng)\n",
    "\n",
    "\tdef __len__(self) -> int:\n",
    "\t\treturn self._max_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageDataSource(data_dir, 'train')\n",
    "train_class_p = 1 / (np.stack([(train_dataset.labels == i).sum() for i in range(num_classes)]))\n",
    "train_data_p = train_class_p[train_dataset.labels]\n",
    "train_data_p /= train_data_p.sum()\n",
    "train_steps_per_epoch = len(train_dataset) // batch_size + 1\n",
    "\n",
    "train_sampler_fn = partial(\n",
    "\tWeightedIndexSampler,\n",
    "\tweights=train_data_p,\n",
    "\tnum_epochs=1,\n",
    ")\n",
    "train_loader_fn = partial(\n",
    "\tpygrain.DataLoader,\n",
    "\tdata_source=train_dataset,\n",
    "\toperations=[\n",
    "\t\tpygrain.Batch(batch_size=batch_size, drop_remainder=False),\n",
    "\t\tImageTransform(train_transform),\n",
    "\t],\n",
    "\tworker_count=2,\n",
    "\tshard_options=pygrain.NoSharding(),\n",
    ")\n",
    "train_steps_per_epoch = len(train_dataset) // batch_size + 1\n",
    "\n",
    "test_dataset = ImageDataSource(data_dir, 'test')\n",
    "test_sampler = pygrain.IndexSampler(\n",
    "\tnum_records=len(test_dataset),\n",
    "\tnum_epochs=1,\n",
    "\tshard_options=pygrain.NoSharding(),\n",
    "\tshuffle=False,\n",
    "\tseed=0,\n",
    ")\n",
    "test_loader = pygrain.DataLoader(\n",
    "\tdata_source=test_dataset,\n",
    "\toperations=[\n",
    "\t\tpygrain.Batch(batch_size=batch_size, drop_remainder=False),\n",
    "\t\tImageTransform(test_transform),\n",
    "\t],\n",
    "\tsampler=test_sampler,\n",
    "\tworker_count=2,\n",
    ")\n",
    "test_steps_per_epoch = len(test_dataset) // batch_size + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "We define a simple metrics aggregator below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Metric:\n",
    "\ttotal: float = 0.\n",
    "\tprevious: float = 0.\n",
    "\tcounter: int = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics:\n",
    "\tdef __init__(self, metrics: list[str]) -> None:\n",
    "\t\tself.keys = metrics\n",
    "\t\tself.history = []\n",
    "\t\tself.reset()\n",
    "\n",
    "\tdef reset(self) -> None:\n",
    "\t\tif hasattr(self, 'metrics'):\n",
    "\t\t\tself.history.append(self.epoch_dict)\n",
    "\t\tself.metrics = {k: Metric() for k in self.keys}\n",
    "\n",
    "\tdef update(self, metrics: dict[str, float|int]) -> None:\n",
    "\t\tfor k, v in metrics.items():\n",
    "\t\t\tself.metrics[k].total += v\n",
    "\t\t\tself.metrics[k].previous = v\n",
    "\t\t\tself.metrics[k].counter += 1\n",
    "\n",
    "\t@property\n",
    "\tdef epoch_dict(self) -> dict[str, float]:\n",
    "\t\treturn {k: v.total / v.counter for k, v in self.metrics.items()}\n",
    "\n",
    "\t@property\n",
    "\tdef epoch(self) -> str:\n",
    "\t\treturn '\\t'.join([f'{k}: {v.total / v.counter:.4f}' for k, v in self.metrics.items()])\n",
    "\n",
    "\t@property\n",
    "\tdef previous(self) -> str:\n",
    "\t\treturn ', '.join([f'{k}: {v.previous:.4f}' for k, v in self.metrics.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_acc(preds: jnp.ndarray, labels: jnp.ndarray) -> float:\n",
    "\treturn (preds.argmax(axis=-1) == labels).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_metrics(metrics, loss, preds, labels):\n",
    "\taccuracy = calc_acc(preds, labels)\n",
    "\tmetrics.update({\n",
    "\t\t'loss': loss,\n",
    "\t\t'accuracy': accuracy,\n",
    "\t})\n",
    "\treturn metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=qnn_wires)\n",
    "\n",
    "@partial(jax.jit, static_argnames=('wires',))\n",
    "@qml.qnode(dev) #let params have uh 10 qubits (we're going to cry)\n",
    "def learnable_qnn_circuit(param, phi, wires):\n",
    "\tfor wire in range(wires):\n",
    "\t\tqml.RY(np.pi * (param[0][wire][0] * phi[wire] + param[0][wire][1]), wires=wire)\n",
    "\t\tqml.RX(param[0][wire][2], wires=wire)\n",
    "\n",
    "\tfor layer_weights in param[2:]:\n",
    "\t\tfor wire in range(wires):\n",
    "\t\t\tqml.Rot(*layer_weights[wire], wires=wire)\n",
    "\t\tfor wire in range(wires):\n",
    "\t\t\tqml.CNOT(wires=[wire, (wire+1) % wires])\n",
    "\n",
    "\treturn qml.expval(qml.PauliZ(0))\n",
    "\n",
    "\n",
    "class LearnableQNN(nn.Module):\n",
    "\twires: int\n",
    "\tlayers: int\n",
    "\n",
    "\tdef setup(self):\n",
    "\t\tself.qnn_params = self.param('qnn_params', nn.initializers.uniform(scale=2*jnp.pi), (self.wires, self.layers, 3))\n",
    "\t\tself.kernel_width = int(self.wires**0.5)\n",
    "\n",
    "\tdef __call__(self, x):\n",
    "\t\tn = x.shape[0]\n",
    "\t\tpatches = pix.extract_patches(\n",
    "\t\t\timages=x,\n",
    "\t\t\tsizes=(1, self.kernel_width, self.kernel_width, 1),\n",
    "\t\t\tstrides=(1, self.kernel_width, self.kernel_width, 1),\n",
    "\t\t\trates=(1, 1, 1, 1),\n",
    "\t\t\tpadding='VALID',\n",
    "\t\t)\n",
    "\t\tpatches = patches.reshape(-1, self.wires)\n",
    "\t\treturn jax.vmap(learnable_qnn_circuit, in_axes=(None, 0, None))(self.qnn_params, patches, self.wires).reshape(n, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicLinearModel(nn.Module):\n",
    "\tnum_classes: int\n",
    "\n",
    "\t@nn.compact\n",
    "\tdef __call__(self, x: jnp.ndarray):\n",
    "\t\tx = nn.Dense(\n",
    "\t\t\tself.num_classes, name='head', kernel_init=nn.zeros\n",
    "\t\t)(x)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequential(nn.Module):\n",
    "\tlayers: list[nn.Module]\n",
    "\n",
    "\t@nn.compact\n",
    "\tdef __call__(self, x: jnp.ndarray):\n",
    "\t\tfor layer in self.layers:\n",
    "\t\t\tx = layer(x)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hf(model_class, model_name):\n",
    "\tprocessor = AutoProcessor.from_pretrained(model_name)\n",
    "\tmodel = model_class.from_pretrained(model_name)\n",
    "\tmodule = model.module\n",
    "\tvariables = model.params\n",
    "\treturn module, variables, processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_state(module, rng, lr, num_epochs, train_steps_per_epoch, print_summary):\n",
    "\tvariables = module.init(rng, jnp.empty([1, image_size, image_size, 3]))\n",
    "\tparams = variables['params']\n",
    "\n",
    "\tlr_schedule = optax.cosine_onecycle_schedule(\n",
    "\t\ttransition_steps=num_epochs * train_steps_per_epoch,\n",
    "\t\tpeak_value=lr,\n",
    "\t\tpct_start=.1,\n",
    "\t\tfinal_div_factor=1000,\n",
    "\t)\n",
    "\tsolver = optax.yogi(lr_schedule)\n",
    "\n",
    "\tif print_summary:\n",
    "\t\tprint(module.tabulate(rng, jnp.empty((1, image_size, image_size, 3)), compute_flops=True, compute_vjp_flops=True))\n",
    "\n",
    "\treturn train_state.TrainState.create(\n",
    "\t\tapply_fn=module.apply,\n",
    "\t\tparams=params,\n",
    "\t\ttx=solver,\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def train_step(state, images, labels):\n",
    "\tdef forward_and_loss(params, images, labels):\n",
    "\t\tpreds = state.apply_fn({ 'params': params }, images)\n",
    "\t\tloss = optax.losses.softmax_cross_entropy_with_integer_labels(\n",
    "\t\t\tlogits=preds, labels=labels\n",
    "\t\t).mean()\n",
    "\t\treturn loss, preds\n",
    "\n",
    "\t(loss, preds), grads = jax.value_and_grad(forward_and_loss, has_aux=True)(state.params, images, labels)\n",
    "\tstate = state.apply_gradients(grads=grads)\n",
    "\treturn state, loss, preds\n",
    "\n",
    "@jax.jit\n",
    "def test_step(state, images, labels):\n",
    "\tpreds = state.apply_fn({ 'params': state.params }, images)\n",
    "\tloss = optax.losses.softmax_cross_entropy_with_integer_labels(\n",
    "\t\tlogits=preds, labels=labels\n",
    "\t).mean()\n",
    "\treturn state, loss, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(epoch_type, state, train_loader, train_steps_per_epoch, metrics):\n",
    "\tassert epoch_type in ['Train', 'Test']\n",
    "\tfor images, labels in (pbar := tqdm(train_loader, total=train_steps_per_epoch, desc=epoch_type, leave=False)):\n",
    "\t\tif epoch_type == 'Train':\n",
    "\t\t\tstate, loss, preds = train_step(state, images, labels)\n",
    "\t\telse:\n",
    "\t\t\tstate, loss, preds = test_step(state, images, labels)\n",
    "\t\tupdate_metrics(metrics, loss, preds, labels)\n",
    "\t\tpbar.set_postfix_str(metrics.previous)\n",
    "\n",
    "\ttqdm.write(f'   -> {epoch_type}:\\t{metrics.epoch}')\n",
    "\tmetrics.reset()\n",
    "\treturn state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qnn_train_metrics = Metrics(['loss', 'accuracy'])\n",
    "qnn_test_metrics = Metrics(['loss', 'accuracy'])\n",
    "cnn_train_metrics = Metrics(['loss', 'accuracy'])\n",
    "cnn_test_metrics = Metrics(['loss', 'accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, qnn_init_key, cnn_init_key = jax.random.split(key, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qnn_module = Sequential(layers=[LearnableQNN(wires=qnn_wires, layers=qnn_layers), BasicLinearModel(num_classes=10)])\n",
    "qnn_state = create_train_state(qnn_module, qnn_init_key, lr, num_epochs, train_steps_per_epoch, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in trange(1, num_epochs+1, desc='QNN'):\n",
    "\ttrain_sampler = train_sampler_fn(seed=epoch)\n",
    "\ttrain_loader = train_loader_fn(sampler=train_sampler)\n",
    "\n",
    "\ttqdm.write(f'Epoch {epoch}/{num_epochs}')\n",
    "\n",
    "\tqnn_state = run_epoch('Train', qnn_state, train_loader, train_steps_per_epoch, qnn_train_metrics)\n",
    "\tqnn_state = run_epoch('Test', qnn_state, test_loader, test_steps_per_epoch, qnn_test_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
