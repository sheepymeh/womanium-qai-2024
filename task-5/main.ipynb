{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import flax\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state\n",
    "import optax\n",
    "import dm_pix as pix\n",
    "import pennylane as qml\n",
    "import orbax.checkpoint as ocp\n",
    "\n",
    "from tqdm.auto import tqdm, trange\n",
    "from grain import python as pygrain\n",
    "\n",
    "from resnet import ResNet18\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from collections import defaultdict\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 4\n",
    "lr = 1e-4\n",
    "data_dir = 'data'\n",
    "output_dir = 'results'\n",
    "seed = 42\n",
    "dataloader_workers = 4\n",
    "num_classes = 6\n",
    "qnn_wires = 4\n",
    "qnn_layers = 2\n",
    "image_size = 224\n",
    "mean = jnp.array([0.24085431])\n",
    "var = jnp.array([0.01992414])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_images(images: jax.Array) -> jax.Array:\n",
    "\timages /= 255\n",
    "\timages = jax.nn.standardize(images, mean=mean, variance=var, axis=(1, 2))\n",
    "\n",
    "\treturn images\n",
    "\n",
    "@jax.jit\n",
    "def train_transform(images: jax.Array, key: jax.Array) -> jax.Array:\n",
    "\tn, h, w, c = images.shape\n",
    "\n",
    "\timages = jax.image.resize(images, (n, int(1.2 * image_size), int(1.2 * image_size), c), method='bicubic')\n",
    "\tkey, flip_lr_key, brightness_key, rotate_key, crop_key = jax.random.split(key, 5)\n",
    "\timages = pix.random_flip_left_right(flip_lr_key, images)\n",
    "\timages = pix.random_brightness(brightness_key, images, 75)\n",
    "\tangles = jax.random.uniform(rotate_key, shape=images.shape[0], minval=-15, maxval=15) / 180 * jnp.pi\n",
    "\timages = jax.vmap(pix.rotate, in_axes=[0, 0], out_axes=0)(images, angles)\n",
    "\timages = pix.random_crop(crop_key, images, (n, image_size, image_size, c))\n",
    "\timages = normalize_images(images)\n",
    "\n",
    "\treturn images\n",
    "\n",
    "@jax.jit\n",
    "def test_transform(images: jax.Array, key: jax.Array) -> jax.Array:\n",
    "\tn, h, w, c = images.shape\n",
    "\n",
    "\timages = jax.image.resize(images, (n, image_size, image_size, c), method='bicubic')\n",
    "\timages = normalize_images(images)\n",
    "\n",
    "\treturn images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageTransform(pygrain.RandomMapTransform):\n",
    "\tdef __init__(self, transform_fn):\n",
    "\t\tself.transform_fn = transform_fn\n",
    "\n",
    "\tdef random_map(self, data: tuple[np.ndarray, np.ndarray], rng: np.random.Generator) -> tuple[jax.Array, jax.Array]:\n",
    "\t\tfnames, images, labels = data\n",
    "\t\timages, labels = jnp.array(images), jnp.array(labels)\n",
    "\n",
    "\t\tif len(images.shape) == 3:\n",
    "\t\t\timages = images[:, :, :, None]\n",
    "\n",
    "\t\tkey = jax.random.PRNGKey(rng.integers(0, 2**32))\n",
    "\t\timages = self.transform_fn(images, key)\n",
    "\t\treturn fnames, images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataSource(pygrain.RandomAccessDataSource[tuple[Image.Image, int]]):\n",
    "\tdef __init__(self, path, split, num_classes = 6):\n",
    "\t\tself.image_dir = os.path.join(path, split)\n",
    "\t\twith open(os.path.join(self.image_dir, f'{split}.json')) as f:\n",
    "\t\t\tdata = json.load(f)\n",
    "\t\t\tself.images = tuple(data.keys())\n",
    "\t\t\tself.labels = np.array(tuple(data.values()))\n",
    "\t\tself.num_classes = num_classes\n",
    "\n",
    "\tdef __len__(self) -> int:\n",
    "\t\treturn len(self.images)\n",
    "\n",
    "\tdef __getitem__(self, idx) -> tuple[Image.Image, int]:\n",
    "\t\timage_path = os.path.join(self.image_dir, self.images[idx])\n",
    "\t\timage = Image.open(image_path).convert('RGB')\n",
    "\t\tlabel = self.labels[idx].item()\n",
    "\t\treturn self.images[idx], image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Index Sampler\n",
    "\n",
    "As the dataset is very imbalanced, we need to use a weighted sampler to ensure that each class is represented equally. This class is intended to work similarly to the [PyTorch Weighted Random Sampler](https://pytorch.org/docs/stable/data.html#torch.utils.data.WeightedRandomSampler)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedIndexSampler(pygrain.Sampler):\n",
    "\tdef __init__(self, weights: np.ndarray, seed: int, num_epochs: int = 1):\n",
    "\t\tassert num_epochs > 0\n",
    "\t\tself._num_records = len(weights)\n",
    "\t\tself._max_index = self._num_records * num_epochs\n",
    "\t\tself._weights = weights\n",
    "\t\tself._seed = seed\n",
    "\t\tself._rng = np.random.Generator(np.random.Philox(self._seed))\n",
    "\t\tself._record_keys = self._rng.choice(self._num_records, size=self._max_index, replace=True, p=self._weights)\n",
    "\n",
    "\tdef __getitem__(self, index: int) -> pygrain.RecordMetadata:\n",
    "\t\tif not 0 <= index < self._max_index:\n",
    "\t\t\traise IndexError(\n",
    "\t\t\t\tf\"RecordMetadata object index is out of bounds; Got index {index},\"\n",
    "\t\t\t\tf\" allowed indices should be in [0, {self._max_index}]\"\n",
    "\t\t\t)\n",
    "\n",
    "\t\trecord_key = self._record_keys[index]\n",
    "\t\trng = np.random.Generator(np.random.Philox(key=self._seed + index))\n",
    "\t\treturn pygrain.RecordMetadata(index, record_key, rng)\n",
    "\n",
    "\tdef __len__(self) -> int:\n",
    "\t\treturn self._max_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageDataSource(data_dir, 'train')\n",
    "train_class_p = 1 / (np.stack([(train_dataset.labels == i).sum() for i in range(num_classes)]))\n",
    "train_data_p = train_class_p[train_dataset.labels]\n",
    "train_data_p /= train_data_p.sum()\n",
    "steps_per_epoch = len(train_dataset) // batch_size + 1\n",
    "\n",
    "train_sampler_fn = partial(\n",
    "\tWeightedIndexSampler,\n",
    "\tweights=train_data_p,\n",
    "\tnum_epochs=1,\n",
    ")\n",
    "train_loader_fn = partial(\n",
    "\tpygrain.DataLoader,\n",
    "\tdata_source=train_dataset,\n",
    "\toperations=[\n",
    "\t\tpygrain.Batch(batch_size=batch_size, drop_remainder=False),\n",
    "\t\tImageTransform(train_transform),\n",
    "\t],\n",
    "\tworker_count=2,\n",
    "\tshard_options=pygrain.NoSharding(),\n",
    ")\n",
    "steps_per_epoch = len(train_dataset) // batch_size + 1\n",
    "\n",
    "test_dataset = ImageDataSource(data_dir, 'test')\n",
    "test_sampler = pygrain.IndexSampler(\n",
    "\tnum_records=len(test_dataset),\n",
    "\tnum_epochs=1,\n",
    "\tshard_options=pygrain.NoSharding(),\n",
    "\tshuffle=False,\n",
    "\tseed=0,\n",
    ")\n",
    "test_loader = pygrain.DataLoader(\n",
    "\tdata_source=test_dataset,\n",
    "\toperations=[\n",
    "\t\tpygrain.Batch(batch_size=batch_size, drop_remainder=False),\n",
    "\t\tImageTransform(test_transform),\n",
    "\t],\n",
    "\tsampler=test_sampler,\n",
    "\tworker_count=2,\n",
    ")\n",
    "test_steps_per_epoch = len(test_dataset) // batch_size + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "We define a simple metrics aggregator below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Metric:\n",
    "\ttotal: float = 0.\n",
    "\tprevious: float = 0.\n",
    "\tcounter: int = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics:\n",
    "\tdef __init__(self, metrics: list[str]) -> None:\n",
    "\t\tself.keys = metrics\n",
    "\t\tself.history = []\n",
    "\t\tself.reset()\n",
    "\n",
    "\tdef reset(self) -> None:\n",
    "\t\tif hasattr(self, 'metrics'):\n",
    "\t\t\tself.history.append(self.epoch_dict)\n",
    "\t\tself.metrics = {k: Metric() for k in self.keys}\n",
    "\n",
    "\tdef update(self, metrics: dict[str, float|int]) -> None:\n",
    "\t\tfor k, v in metrics.items():\n",
    "\t\t\tself.metrics[k].total += v\n",
    "\t\t\tself.metrics[k].previous = v\n",
    "\t\t\tself.metrics[k].counter += 1\n",
    "\n",
    "\tdef save(self, path: str) -> None:\n",
    "\t\twith open(path, 'w') as f:\n",
    "\t\t\tjson.dump(self.history, f)\n",
    "\n",
    "\t@property\n",
    "\tdef epoch_dict(self) -> dict[str, float]:\n",
    "\t\treturn {k: v.total / v.counter for k, v in self.metrics.items()}\n",
    "\n",
    "\t@property\n",
    "\tdef epoch(self) -> str:\n",
    "\t\treturn '\\t'.join([f'{k}: {v.total / v.counter:.4f}' for k, v in self.metrics.items()])\n",
    "\n",
    "\t@property\n",
    "\tdef previous(self) -> str:\n",
    "\t\treturn ', '.join([f'{k}: {v.previous:.4f}' for k, v in self.metrics.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_acc(preds: jnp.ndarray, labels: jnp.ndarray) -> float:\n",
    "\treturn (preds.argmax(axis=-1) == labels).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_video_acc(all_preds: dict[str, list]) -> float:\n",
    "\tcorrect = 0\n",
    "\tfor label, preds in all_preds.values():\n",
    "\t\tpred = max(preds, key=preds.count)\n",
    "\t\tif pred == label:\n",
    "\t\t\tcorrect += 1\n",
    "\treturn correct / len(all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_metrics(metrics, loss, preds, labels):\n",
    "\taccuracy = calc_acc(preds, labels)\n",
    "\tmetrics.update({\n",
    "\t\t'loss': loss,\n",
    "\t\t'accuracy': accuracy,\n",
    "\t})\n",
    "\treturn metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=qnn_wires)\n",
    "\n",
    "@partial(jax.jit, static_argnames=('wires',))\n",
    "@qml.qnode(dev)\n",
    "def learnable_qnn_circuit(param, phi, wires):\n",
    "\tfor wire in range(wires):\n",
    "\t\tqml.Rot(*(np.pi * phi[wire] * param[0][wire]), wires=wire)\n",
    "\n",
    "\tfor layer_weights in param[1:]:\n",
    "\t\tfor wire in range(wires):\n",
    "\t\t\tqml.Rot(*layer_weights[wire], wires=wire)\n",
    "\t\tfor wire in range(wires):\n",
    "\t\t\tqml.CNOT(wires=[wire, (wire+1) % wires])\n",
    "\n",
    "\treturn qml.expval(qml.PauliZ(0))\n",
    "\n",
    "class LearnableQNN(nn.Module):\n",
    "\twires: int\n",
    "\tlayers: int\n",
    "\n",
    "\tdef setup(self):\n",
    "\t\tself.qnn_params = self.param('qnn_params', nn.initializers.uniform(scale=2*jnp.pi), (self.wires, self.layers, 3))\n",
    "\t\tself.kernel_width = int(self.wires**0.5)\n",
    "\n",
    "\tdef __call__(self, x):\n",
    "\t\tn = x.shape[0]\n",
    "\t\tpatches = pix.extract_patches(\n",
    "\t\t\timages=x,\n",
    "\t\t\tsizes=(1, self.kernel_width, self.kernel_width, 1),\n",
    "\t\t\tstrides=(1, self.kernel_width, self.kernel_width, 1),\n",
    "\t\t\trates=(1, 1, 1, 1),\n",
    "\t\t\tpadding='VALID',\n",
    "\t\t)\n",
    "\t\tpatches = patches.reshape(-1, self.wires)\n",
    "\t\treturn jax.vmap(learnable_qnn_circuit, in_axes=(None, 0, None))(self.qnn_params, patches, self.wires).reshape(n, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "\tnum_classes: int\n",
    "\n",
    "\t@nn.compact\n",
    "\tdef __call__(self, x: jnp.ndarray):\n",
    "\t\tx = x.reshape((x.shape[0], -1))\n",
    "\t\tx = nn.Dense(\n",
    "\t\t\tself.num_classes, name='head', kernel_init=nn.zeros\n",
    "\t\t)(x)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedModel(nn.Module):\n",
    "\tbackbone: nn.Module\n",
    "\tqnn: nn.Module\n",
    "\tclassifier: nn.Module\n",
    "\n",
    "\t@nn.compact\n",
    "\tdef __call__(\n",
    "\t\tself,\n",
    "\t\tx: jnp.ndarray,\n",
    "\t\tbackbone_kwargs: dict = {},\n",
    "\t\tqnn_kwargs: dict = {},\n",
    "\t\tclassifier_kwargs: dict = {},\n",
    "\t):\n",
    "\t\tx = self.backbone(x, **backbone_kwargs)\n",
    "\t\tx = self.qnn(x, **qnn_kwargs)\n",
    "\t\tx = self.classifier(x, **classifier_kwargs)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_module(rng, image_size):\n",
    "\tbackbone = ResNet18()\n",
    "\tmodule = CombinedModel(\n",
    "\t\tbackbone=backbone,\n",
    "\t\tqnn=LearnableQNN(qnn_wires, qnn_layers),\n",
    "\t\tclassifier=Classifier(num_classes),\n",
    "\t)\n",
    "\tvariables = module.init(rng, jnp.empty([1, image_size, image_size, 3]))\n",
    "\tparams = variables['params']\n",
    "\tbatch_stats = variables['batch_stats']\n",
    "\treturn module, params, batch_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainState(train_state.TrainState):\n",
    "\tbatch_stats: dict\n",
    "\n",
    "def create_train_state(module, params, batch_stats, rng, lr, num_epochs, train_steps_per_epoch, print_summary):\n",
    "\tlr_schedule = optax.cosine_onecycle_schedule(\n",
    "\t\ttransition_steps=num_epochs * train_steps_per_epoch,\n",
    "\t\tpeak_value=lr,\n",
    "\t\tpct_start=.1,\n",
    "\t\tfinal_div_factor=1000,\n",
    "\t)\n",
    "\tsolver = optax.adamw(lr_schedule, weight_decay=0.001)\n",
    "\n",
    "\tif print_summary:\n",
    "\t\tprint(module.tabulate(rng, jnp.empty((1, image_size, image_size, 3)), compute_flops=True, compute_vjp_flops=True))\n",
    "\n",
    "\treturn TrainState.create(\n",
    "\t\tapply_fn=module.apply,\n",
    "\t\tparams=params,\n",
    "\t\tbatch_stats=batch_stats,\n",
    "\t\ttx=solver,\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def train_step(state: TrainState, images, labels):\n",
    "\tdef forward_and_loss(params, batch_stats, images, labels):\n",
    "\t\tpreds, updates = state.apply_fn({ 'params': params, 'batch_stats': batch_stats }, images, mutable=['batch_stats'], backbone_kwargs={ 'train': True })\n",
    "\t\tloss = optax.losses.softmax_cross_entropy_with_integer_labels(\n",
    "\t\t\tlogits=preds, labels=labels\n",
    "\t\t).mean()\n",
    "\t\treturn loss, (preds, updates)\n",
    "\n",
    "\t(loss, (preds, updates)), grads = jax.value_and_grad(forward_and_loss, has_aux=True)(state.params, state.batch_stats, images, labels)\n",
    "\tstate = state.apply_gradients(grads=grads)\n",
    "\tstate = state.replace(batch_stats=updates['batch_stats'])\n",
    "\treturn state, loss, preds\n",
    "\n",
    "@jax.jit\n",
    "def test_step(state, images, labels):\n",
    "\tpreds = state.apply_fn({ 'params': state.params, 'batch_stats': state.batch_stats }, images, backbone_kwargs={ 'train': False })\n",
    "\tloss = optax.losses.softmax_cross_entropy_with_integer_labels(\n",
    "\t\tlogits=preds, labels=labels\n",
    "\t).mean()\n",
    "\treturn state, loss, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(epoch_type, state, dataloader, steps_per_epoch, metrics):\n",
    "\tassert epoch_type in ['Train', 'Test']\n",
    "\tall_preds = defaultdict(lambda: [0, []])\n",
    "\n",
    "\tfor fnames, images, labels in (pbar := tqdm(dataloader, total=steps_per_epoch, desc=epoch_type, leave=False)):\n",
    "\t\tif epoch_type == 'Train':\n",
    "\t\t\tstate, loss, preds = train_step(state, images, labels)\n",
    "\t\telse:\n",
    "\t\t\tstate, loss, preds = test_step(state, images, labels)\n",
    "\n",
    "\t\tfor fname, pred, label in zip(fnames, preds, labels):\n",
    "\t\t\tfolder = fname.split('/')[0]\n",
    "\t\t\tall_preds[folder][0] = label.item()\n",
    "\t\t\tall_preds[folder][1].append(pred.argmax().item())\n",
    "\n",
    "\t\tupdate_metrics(metrics, loss.item(), preds, labels)\n",
    "\t\tpbar.set_postfix_str(metrics.previous)\n",
    "\n",
    "\tvideo_acc = calc_video_acc(all_preds)\n",
    "\ttqdm.write(f'   -> {epoch_type}:\\t{metrics.epoch}\\tvideo acc: {video_acc:.4f}')\n",
    "\tmetrics.reset()\n",
    "\treturn state, all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qnn_train_metrics = Metrics(['loss', 'accuracy'])\n",
    "qnn_test_metrics = Metrics(['loss', 'accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, qnn_init_key = jax.random.split(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qnn_module, params, batch_stats = create_module(qnn_init_key, image_size)\n",
    "qnn_state = create_train_state(qnn_module, params, batch_stats, qnn_init_key, lr, num_epochs, steps_per_epoch, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_preds = []\n",
    "all_test_preds = []\n",
    "\n",
    "for epoch in trange(1, num_epochs+1, desc='QNN'):\n",
    "\ttrain_sampler = train_sampler_fn(seed=epoch)\n",
    "\tdataloader = train_loader_fn(sampler=train_sampler)\n",
    "\n",
    "\ttqdm.write(f'Epoch {epoch}/{num_epochs}')\n",
    "\n",
    "\tqnn_state, train_preds = run_epoch('Train', qnn_state, dataloader, steps_per_epoch, qnn_train_metrics)\n",
    "\tqnn_state, test_preds = run_epoch('Test', qnn_state, test_loader, test_steps_per_epoch, qnn_test_metrics)\n",
    "\n",
    "\tall_train_preds.append(train_preds)\n",
    "\tall_test_preds.append(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ocp.test_utils.erase_and_create_empty(output_dir)\n",
    "\n",
    "with open(os.path.join(output_dir, 'qnn_train_preds.json'), 'w') as f:\n",
    "\tjson.dump(all_train_preds, f)\n",
    "\n",
    "with open(os.path.join(output_dir, 'qnn_train_metrics.json'), 'w') as f:\n",
    "\thistory = [{\n",
    "\t\t**metrics,\n",
    "\t\t'video_acc': calc_video_acc(preds),\n",
    "\t} for metrics, preds in zip(\n",
    "\t\tqnn_train_metrics.history,\n",
    "\t\tall_train_preds,\n",
    "\t)]\n",
    "\tjson.dump(history, f)\n",
    "\n",
    "with open(os.path.join(output_dir, 'qnn_test_preds.json'), 'w') as f:\n",
    "\tjson.dump(all_test_preds, f)\n",
    "\n",
    "with open(os.path.join(output_dir, 'qnn_test_metrics.json'), 'w') as f:\n",
    "\thistory = [{\n",
    "\t\t**metrics,\n",
    "\t\t'video_acc': calc_video_acc(preds),\n",
    "\t} for metrics, preds in zip(\n",
    "\t\tqnn_test_metrics.history,\n",
    "\t\tall_test_preds,\n",
    "\t)]\n",
    "\tjson.dump(history, f)\n",
    "\n",
    "checkpointer = ocp.StandardCheckpointer()\n",
    "checkpoint_path = os.path.abspath(os.path.join(output_dir, 'checkpoint'))\n",
    "checkpointer.save(checkpoint_path, qnn_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
