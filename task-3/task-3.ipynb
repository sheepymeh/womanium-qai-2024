{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3 - MNIST Dataset\n",
    "\n",
    "In this notebook, we present our solution to task 3, where we train a QML model on the MNIST dataset. We make the following improvements to the tutorial presented\n",
    "\n",
    "* Testing on the Fashion MNIST dataset\n",
    "* Allow the QNN parameters to be trained\n",
    "* Use JAX instead of Keras\n",
    "* Use `jax.vmap` to speed up the QNN\n",
    "* Add augmentations to the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "import flax\n",
    "from flax import linen as nn\n",
    "import optax\n",
    "\n",
    "import grain.python as pygrain\n",
    "import dm_pix\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from functools import partial\n",
    "from dataclasses import dataclass\n",
    "from itertools import combinations\n",
    "\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 30\n",
    "batch_size = 32\n",
    "lr = 1e-3\n",
    "\n",
    "SAVE_PATH = \"data/\"\n",
    "np.random.seed(0)\n",
    "key = jax.random.PRNGKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "We use the [Google Grain](https://github.com/google/grain) library to load our dataset. We use rotational augmentations to improve generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(url: str, fname: str, chunk_size=1024):\n",
    "\tif os.path.exists(fname):\n",
    "\t\treturn\n",
    "\n",
    "\tresp = requests.get(url, stream=True)\n",
    "\ttotal = int(resp.headers.get('content-length', 0))\n",
    "\twith open(fname, 'wb') as file, tqdm(\n",
    "\t\tdesc=fname,\n",
    "\t\ttotal=total,\n",
    "\t\tunit='iB',\n",
    "\t\tunit_scale=True,\n",
    "\t\tunit_divisor=1024,\n",
    "\t) as bar:\n",
    "\t\tfor data in resp.iter_content(chunk_size=chunk_size):\n",
    "\t\t\tsize = file.write(data)\n",
    "\t\t\tbar.update(size)\n",
    "\n",
    "class ImageDataSource(pygrain.RandomAccessDataSource[tuple[np.ndarray, np.ndarray]]):\n",
    "\tdef __init__(self, path, split):\n",
    "\t\tdownload('https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz', os.path.join(path, 'mnist.npz'))\n",
    "\t\tdata = np.load(os.path.join(path, 'mnist.npz'))\n",
    "\t\tself.images = data[f'x_{split}'][..., np.newaxis]\n",
    "\t\tself.labels = data[f'y_{split}']\n",
    "\n",
    "\tdef __len__(self) -> int:\n",
    "\t\treturn len(self.images)\n",
    "\n",
    "\tdef __getitem__(self, idx) -> tuple[np.ndarray, np.ndarray]:\n",
    "\t\timage, label = self.images[idx], self.labels[idx]\n",
    "\t\treturn image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageTransform(pygrain.RandomMapTransform):\n",
    "\tdef __init__(self, split, mean, var):\n",
    "\t\tself.train = split == 'train'\n",
    "\t\tself.mean = jnp.array(mean)\n",
    "\t\tself.var = jnp.array(var)\n",
    "\n",
    "\t# @jax.jit\n",
    "\tdef random_map(self, data: tuple[np.ndarray, np.ndarray], rng: np.random.Generator) -> tuple[jax.Array, jax.Array]:\n",
    "\t\timages, labels = data\n",
    "\t\timages, labels = jnp.array(images), jnp.array(labels)\n",
    "\n",
    "\t\tif self.train:\n",
    "\t\t\tkey = jax.random.PRNGKey(rng.integers(0, 2**32))\n",
    "\t\t\tangle = jax.random.uniform(key, shape=images.shape[0], minval=-10, maxval=10) / 180 * jnp.pi\n",
    "\t\t\timages = jax.vmap(\n",
    "\t\t\t\tpartial(dm_pix.rotate, mode='constant', cval=255),\n",
    "\t\t\t\tin_axes=[0, 0], out_axes=0\n",
    "\t\t\t)(images, angle)\n",
    "\n",
    "\t\timages /= 255\n",
    "\t\timages = jax.nn.standardize(\n",
    "\t\t\timages,\n",
    "\t\t\tmean=self.mean,\n",
    "\t\t\tvariance=self.var,\n",
    "\t\t\taxis=(2, 3)\n",
    "\t\t)\n",
    "\t\treturn images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing data loaders\n",
    "\n",
    "We use the known mean and std values for the MNIST dataset. However, we use the variance instead of the std as that is the expected input for `dm-pix`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageDataSource(SAVE_PATH, 'train')\n",
    "train_sampler_fn = partial(\n",
    "\tpygrain.IndexSampler,\n",
    "\tnum_records=len(train_dataset),\n",
    "\tnum_epochs=1,\n",
    "\tshard_options=pygrain.NoSharding(),\n",
    "\tshuffle=True,\n",
    ")\n",
    "train_loader_fn = partial(\n",
    "\tpygrain.DataLoader,\n",
    "\tdata_source=train_dataset,\n",
    "\toperations=[\n",
    "\t\tpygrain.Batch(batch_size=batch_size, drop_remainder=False),\n",
    "\t\tImageTransform('train', 0.1307, 0.5551),\n",
    "\t],\n",
    "\tworker_count=2,\n",
    ")\n",
    "train_steps_per_epoch = len(train_dataset) // batch_size + 1\n",
    "\n",
    "test_dataset = ImageDataSource(SAVE_PATH, 'test')\n",
    "test_sampler = pygrain.IndexSampler(\n",
    "\tnum_records=len(test_dataset),\n",
    "\tnum_epochs=1,\n",
    "\tshard_options=pygrain.NoSharding(),\n",
    "\tshuffle=False,\n",
    "\tseed=0,\n",
    ")\n",
    "test_loader = pygrain.DataLoader(\n",
    "\tdata_source=test_dataset,\n",
    "\toperations=[\n",
    "\t\tpygrain.Batch(batch_size=batch_size, drop_remainder=False),\n",
    "\t\tImageTransform('test', 0.1307, 0.5551),\n",
    "\t],\n",
    "\tsampler=test_sampler,\n",
    "\tworker_count=2,\n",
    ")\n",
    "test_steps_per_epoch = len(test_dataset) // batch_size + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "We add a simple metrics aggregator below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Metric:\n",
    "\ttotal: float = 0.\n",
    "\tprevious: float = 0.\n",
    "\tcounter: int = 0\n",
    "\n",
    "class Metrics:\n",
    "\tdef __init__(self, metrics: list[str]) -> None:\n",
    "\t\tself.keys = metrics\n",
    "\t\tself.reset()\n",
    "\n",
    "\tdef reset(self) -> None:\n",
    "\t\tself.metrics = {k: Metric() for k in self.keys}\n",
    "\n",
    "\tdef update(self, metrics: dict[str, float|int]) -> None:\n",
    "\t\tfor k, v in metrics.items():\n",
    "\t\t\tself.metrics[k].total += v\n",
    "\t\t\tself.metrics[k].previous = v\n",
    "\t\t\tself.metrics[k].counter += 1\n",
    "\n",
    "\t@property\n",
    "\tdef epoch_dict(self) -> dict[str, float]:\n",
    "\t\treturn {k: v.total / v.counter for k, v in self.metrics.items()}\n",
    "\n",
    "\t@property\n",
    "\tdef epoch(self) -> str:\n",
    "\t\treturn '\\t'.join([f'{k}: {v.total / v.counter:.4f}' for k, v in self.metrics.items()])\n",
    "\n",
    "\t@property\n",
    "\tdef previous(self) -> str:\n",
    "\t\treturn ', '.join([f'{k}: {v.previous:.4f}' for k, v in self.metrics.items()])\n",
    "\n",
    "def calc_acc(preds: jnp.ndarray, labels: jnp.ndarray) -> float:\n",
    "\treturn (preds.argmax(axis=-1) == labels).mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QML Model\n",
    "\n",
    "Here, we implement a learnable QNN circuit. We use `dm_pix.extract_patches` to extract the patches of the image for the convolution. Then, we use `jax.vmap` to execute the QNN in a vectorized form, returning an array of shape `(batch_size, qnn_output_x * qnn_output_y * qnn_output_channels)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=4)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def learnable_qnn_circuit(param, phi):\n",
    "\tfor wire in range(4):\n",
    "\t\tqml.RY(np.pi * phi[wire], wires=wire)\n",
    "\t\tqml.Rot(*param[wire], wires=wire)\n",
    "\n",
    "\tfor pair in combinations(range(4), 2):\n",
    "\t\tqml.CNOT(wires=pair)\n",
    "\n",
    "\treturn qml.expval(qml.PauliZ(0))\n",
    "\n",
    "\n",
    "class LearnableQNN(nn.Module):\n",
    "\tdef setup(self):\n",
    "\t\tself.params = self.param('params', nn.initializers.uniform(scale=2*jnp.pi), (4, 3))\n",
    "\n",
    "\tdef __call__(self, x):\n",
    "\t\tn = x.shape[0]\n",
    "\t\tpatches = dm_pix.extract_patches(\n",
    "\t\t\timages=x,\n",
    "\t\t\tsizes=(1, 2, 2, 1),\n",
    "\t\t\tstrides=(1, 2, 2, 1),\n",
    "\t\t\trates=(1, 1, 1, 1),\n",
    "\t\t\tpadding='VALID',\n",
    "\t\t)\n",
    "\t\tpatches = patches.reshape(-1, 4)\n",
    "\t\treturn jax.vmap(learnable_qnn_circuit, in_axes=(None, 0))(self.params, patches).reshape(n, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical Model\n",
    "\n",
    "We use a simple linear model to implement the classical head for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicLinearModel(nn.Module):\n",
    "\tnum_classes: int\n",
    "\n",
    "\t@nn.compact\n",
    "\tdef __call__(self, x: jnp.ndarray):\n",
    "\t\tx = nn.Dense(\n",
    "\t\t\tself.num_classes, name='head', kernel_init=nn.zeros\n",
    "\t\t)(x)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequential(nn.Module):\n",
    "\tlayers: list[nn.Module]\n",
    "\n",
    "\t@nn.compact\n",
    "\tdef __call__(self, x: jnp.ndarray):\n",
    "\t\tfor layer in self.layers:\n",
    "\t\t\tx = layer(x)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, init_key = jax.random.split(key)\n",
    "\n",
    "model_qnn = LearnableQNN()\n",
    "model_classic = BasicLinearModel(num_classes=10)\n",
    "model = Sequential(layers=[model_qnn, model_classic])\n",
    "variables = model.init(init_key, jnp.empty((1, 28, 28, 1)))\n",
    "params = variables['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = optax.cosine_onecycle_schedule(\n",
    "\ttransition_steps=n_epochs * train_steps_per_epoch,\n",
    "\tpeak_value=lr,\n",
    "\tpct_start=.2,\n",
    "\tfinal_div_factor=1000,\n",
    ")\n",
    "solver = optax.yogi(lr_schedule)\n",
    "solver_state = solver.init(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics = Metrics(['loss', 'acc'])\n",
    "val_metrics = Metrics(['loss', 'acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_and_loss(variables, images, labels):\n",
    "\tpreds = model.apply(variables, images)\n",
    "\tloss = optax.losses.softmax_cross_entropy_with_integer_labels(preds, labels).mean()\n",
    "\treturn loss, preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in trange(1, n_epochs+1):\n",
    "\ttrain_metrics.reset()\n",
    "\tval_metrics.reset()\n",
    "\n",
    "\ttrain_sampler = train_sampler_fn(seed=epoch)\n",
    "\ttrain_loader = train_loader_fn(sampler=train_sampler)\n",
    "\n",
    "\tfor images, labels in (pbar := tqdm(train_loader, total=train_steps_per_epoch, desc='Training', leave=False)):\n",
    "\t\t(loss, preds), grad = jax.value_and_grad(forward_and_loss, has_aux=True)({ 'params': params }, images, labels)\n",
    "\t\tupdates, solver_state = solver.update(grad['params'], solver_state, params)\n",
    "\t\tparams = optax.apply_updates(params, updates)\n",
    "\n",
    "\t\ttrain_metrics.update({\n",
    "\t\t\t'loss': loss.item(),\n",
    "\t\t\t'acc': calc_acc(preds, labels),\n",
    "\t\t})\n",
    "\t\tpbar.set_postfix_str(train_metrics.previous)\n",
    "\n",
    "\ttqdm.write(f'epoch {epoch}: {train_metrics.epoch}')\n",
    "\n",
    "\tfor images, labels in (pbar := tqdm(test_loader, total=test_steps_per_epoch, desc='Validation', leave=False)):\n",
    "\t\tloss, preds = forward_and_loss({ 'params': params }, images, labels)\n",
    "\n",
    "\t\tval_metrics.update({\n",
    "\t\t\t'loss': loss.item(),\n",
    "\t\t\t'acc': calc_acc(preds, labels),\n",
    "\t\t})\n",
    "\t\tpbar.set_postfix_str(val_metrics.previous)\n",
    "\n",
    "\ttqdm.write(f'  -> val: {val_metrics.epoch}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pennylane-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
